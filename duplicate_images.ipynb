{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit230750f2ffa44fbfaec87aca222121f5",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create a list with all the file paths within a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilePaths(path):\n",
    "    # Function to return a list of files in a path:\n",
    "    # Initialize a list for all the file names\n",
    "    files = list()\n",
    "    # Look for folders in the list\n",
    "    for file in os.listdir(path):\n",
    "        # Concatenate a path for each file\n",
    "        pathfile = os.path.join(path, file)\n",
    "        # Validate if the pathfile is a folder\n",
    "        if os.path.isdir(pathfile):\n",
    "            files = files + getFilePaths(pathfile)\n",
    "        else:\n",
    "            files.append(pathfile)\n",
    "    return files      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe with the list of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd, time, hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                path  \\\n0                           ../Photos copy/.DS_Store   \n1  ../Photos copy/New Folder With Items 5/DSC_003...   \n2  ../Photos copy/New Folder With Items 5/DSC_002...   \n3  ../Photos copy/New Folder With Items 5/DSC_001...   \n4  ../Photos copy/New Folder With Items 5/DSC_001...   \n\n                               hash      filename  count              created  \\\n0  5f27466e92caf57a930058b683ad5f7e     .DS_Store      1  2020-04-09 23:53:43   \n1  b8cc4ead5b44bdd8e994c21287e618e8  DSC_0030.jpg      1  2020-04-09 23:53:43   \n2  683d7efc80e910a2691880ca0ad9d059  DSC_0024.jpg      1  2020-04-09 23:53:43   \n3  689a4e61ff572cb10ca471fb58004df1  DSC_0018.jpg      1  2020-04-09 23:53:43   \n4  4d8c40e515d43b15a2dd6f826fdd1163  DSC_0019.jpg      1  2020-04-09 23:53:43   \n\n              modified  \n0  2020-04-09 18:38:53  \n1  2020-04-07 20:02:04  \n2  2020-04-07 19:59:50  \n3  2020-04-07 19:54:48  \n4  2020-04-07 19:55:54  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>hash</th>\n      <th>filename</th>\n      <th>count</th>\n      <th>created</th>\n      <th>modified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>../Photos copy/.DS_Store</td>\n      <td>5f27466e92caf57a930058b683ad5f7e</td>\n      <td>.DS_Store</td>\n      <td>1</td>\n      <td>2020-04-09 23:53:43</td>\n      <td>2020-04-09 18:38:53</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>../Photos copy/New Folder With Items 5/DSC_003...</td>\n      <td>b8cc4ead5b44bdd8e994c21287e618e8</td>\n      <td>DSC_0030.jpg</td>\n      <td>1</td>\n      <td>2020-04-09 23:53:43</td>\n      <td>2020-04-07 20:02:04</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>../Photos copy/New Folder With Items 5/DSC_002...</td>\n      <td>683d7efc80e910a2691880ca0ad9d059</td>\n      <td>DSC_0024.jpg</td>\n      <td>1</td>\n      <td>2020-04-09 23:53:43</td>\n      <td>2020-04-07 19:59:50</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>../Photos copy/New Folder With Items 5/DSC_001...</td>\n      <td>689a4e61ff572cb10ca471fb58004df1</td>\n      <td>DSC_0018.jpg</td>\n      <td>1</td>\n      <td>2020-04-09 23:53:43</td>\n      <td>2020-04-07 19:54:48</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>../Photos copy/New Folder With Items 5/DSC_001...</td>\n      <td>4d8c40e515d43b15a2dd6f826fdd1163</td>\n      <td>DSC_0019.jpg</td>\n      <td>1</td>\n      <td>2020-04-09 23:53:43</td>\n      <td>2020-04-07 19:55:54</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 656
    }
   ],
   "source": [
    "# Path with the files to look for duplicates\n",
    "path='../Photos copy'\n",
    "# Initialize and empty dataframe with the paths of the files in the given path\n",
    "files_df = pd.DataFrame(getFilePaths(path),columns=['path'])\n",
    "# Initialize Columns for the dataframe \n",
    "files_df['hash'] = 0\n",
    "files_df['filename'] = ''\n",
    "files_df['count'] = 1\n",
    "files_df['created'] = 0\n",
    "files_df['modified'] = 0\n",
    "\n",
    "# Loop to fill the dataframe columns with values\n",
    "for row in range(len(files_df)):\n",
    "    # Load the file\n",
    "    image_file = open(files_df['path'][row],'rb').read()\n",
    "    # Encode the file to a hexagsimal number\n",
    "    files_df['hash'][row] = hashlib.md5(image_file).hexdigest()\n",
    "    # Get the filename of the file\n",
    "    files_df['filename'][row] = os.path.basename(files_df['path'][row])\n",
    "    # Get the created date \n",
    "    files_df['created'][row] = pd.to_datetime(time.ctime(os.path.getctime(files_df['path'][row])))\n",
    "    # Get the modified date \n",
    "    files_df['modified'][row] = pd.to_datetime(time.ctime(os.path.getmtime(files_df['path'][row])))\n",
    "# Print first rows of the dataframe    \n",
    "files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      count\nhash       \nAll       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>hash</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>All</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 657
    }
   ],
   "source": [
    "import numpy as np, datetime\n",
    "reapeated_files_df = files_df.groupby('hash').sum()\n",
    "reapeated_files_df = reapeated_files_df[reapeated_files_df['count'] > 1]\n",
    "pivot_df = pd.pivot_table(reapeated_files_df, values='count', index=['hash'], aggfunc=np.sum, margins=True)\n",
    "now_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "pivot_df.to_csv('repeated_' + now_string + '.csv' )\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No repeated files were found\n"
    }
   ],
   "source": [
    "if pivot_df['count']['All'] ==0:\n",
    "    print('No repeated files were found')\n",
    "\n",
    "else:\n",
    "\n",
    "    repeated_path_df = files_df[files_df['hash'].isin(pivot_df.index.to_list())]\n",
    "    repeated_path_df = repeated_path_df.groupby(['hash','path','created','modified']).sum().sort_values(by=['hash', 'created',                                                          'modified'], ascending=True)\n",
    "    repeated_path_df.to_csv('repeated_list_' + now_string + '.csv' )\n",
    "\n",
    "\n",
    "    repeated_path_df['action'] = ''\n",
    "    repeated_path_df['action'][0] = 'leave' \n",
    "\n",
    "\n",
    "    for i in range(1,len(repeated_path_df.index.get_level_values(1).tolist())):\n",
    "        if repeated_path_df.index.get_level_values(0)[i] == repeated_path_df.index.get_level_values(0)[i-1]:\n",
    "            repeated_path_df['action'][i] = 'delete' \n",
    "        else:\n",
    "            repeated_path_df['action'][i] = 'delete' \n",
    "\n",
    "    repeated_path_df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-659-74065fc78d6b>, line 5)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-659-74065fc78d6b>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print('Duplicated images had been deleted')\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "if pivot_df['count']['All'] ==0:\n",
    "    print('No repeated files were found')\n",
    "\n",
    "else:\n",
    "    for i in range(0,len(repeated_path_df.index.get_level_values(1).tolist())):\n",
    "        if repeated_path_df['action'][i] == 'delete':\n",
    "            #os.remove(repeated_path_df.index.get_level_values(1).tolist()[i])\n",
    " \n",
    "    print('All duplicated images had been deleted')\n"
   ]
  }
 ]
}