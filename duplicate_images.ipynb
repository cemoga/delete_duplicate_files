{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit230750f2ffa44fbfaec87aca222121f5",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create a list with all the file paths within a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilePaths(path):\n",
    "    # Function to return a list of files in a path:\n",
    "    # Initialize a list for all the file names\n",
    "    files = list()\n",
    "    # Look for folders in the list\n",
    "    for file in os.listdir(path):\n",
    "        # Concatenate a path for each file\n",
    "        pathfile = os.path.join(path, file)\n",
    "        # Validate if the pathfile is a folder\n",
    "        if os.path.isdir(pathfile):\n",
    "            # If it is a folder, get the paths of each folder\n",
    "            files = files + getFilePaths(pathfile)\n",
    "        else:\n",
    "            # If it is not a folder add the path to the list\n",
    "            files.append(pathfile)\n",
    "    return files      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe with the list of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd, time, hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path with the files to look for duplicates\n",
    "path='../1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            path  \\\n0  ../1/639a58cd-e467-4187-91fe-35c71cc86970.jpg   \n1  ../1/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg   \n2  ../1/92f5ab2f-15b2-4175-a08d-06c7f66c0e28.jpg   \n3                                 ../1/.DS_Store   \n4  ../1/37f16d12-a798-49a9-a145-e04c167e54c0.jpg   \n\n                               hash                                  filename  \\\n0  374f0604be4b276c023e330f409d2a7b  639a58cd-e467-4187-91fe-35c71cc86970.jpg   \n1  4d0c606b822f16e97762a413b3e102c6  634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg   \n2  07f63c2ed334d6e3c31d13f4030156ed  92f5ab2f-15b2-4175-a08d-06c7f66c0e28.jpg   \n3  d13c0d46e5380fa87709e82d34a48bf5                                 .DS_Store   \n4  afd165573dd62113bdbf71311cbb503f  37f16d12-a798-49a9-a145-e04c167e54c0.jpg   \n\n   count              created             modified  filesize  \n0      1  2020-04-10 21:19:46  2020-04-08 19:08:52     45155  \n1      1  2020-04-10 21:19:46  2020-04-07 11:34:38    158673  \n2      1  2020-04-10 21:19:46  2020-04-07 15:13:26    201558  \n3      1  2020-04-10 21:20:10  2020-04-10 21:20:10      6148  \n4      1  2020-04-10 21:19:46  2020-04-07 15:13:46    180526  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>hash</th>\n      <th>filename</th>\n      <th>count</th>\n      <th>created</th>\n      <th>modified</th>\n      <th>filesize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>../1/639a58cd-e467-4187-91fe-35c71cc86970.jpg</td>\n      <td>374f0604be4b276c023e330f409d2a7b</td>\n      <td>639a58cd-e467-4187-91fe-35c71cc86970.jpg</td>\n      <td>1</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-08 19:08:52</td>\n      <td>45155</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>../1/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg</td>\n      <td>4d0c606b822f16e97762a413b3e102c6</td>\n      <td>634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg</td>\n      <td>1</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 11:34:38</td>\n      <td>158673</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>../1/92f5ab2f-15b2-4175-a08d-06c7f66c0e28.jpg</td>\n      <td>07f63c2ed334d6e3c31d13f4030156ed</td>\n      <td>92f5ab2f-15b2-4175-a08d-06c7f66c0e28.jpg</td>\n      <td>1</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 15:13:26</td>\n      <td>201558</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>../1/.DS_Store</td>\n      <td>d13c0d46e5380fa87709e82d34a48bf5</td>\n      <td>.DS_Store</td>\n      <td>1</td>\n      <td>2020-04-10 21:20:10</td>\n      <td>2020-04-10 21:20:10</td>\n      <td>6148</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>../1/37f16d12-a798-49a9-a145-e04c167e54c0.jpg</td>\n      <td>afd165573dd62113bdbf71311cbb503f</td>\n      <td>37f16d12-a798-49a9-a145-e04c167e54c0.jpg</td>\n      <td>1</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 15:13:46</td>\n      <td>180526</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Initialize and empty dataframe with the paths of the files in the given path\n",
    "files_df = pd.DataFrame(getFilePaths(path),columns=['path'])\n",
    "# Initialize Columns for the dataframe \n",
    "files_df['hash'] = 0\n",
    "files_df['filename'] = ''\n",
    "files_df['count'] = 1\n",
    "files_df['created'] = 0\n",
    "files_df['modified'] = 0\n",
    "files_df['filesize'] = 0\n",
    "\n",
    "# Loop to fill the dataframe columns with values\n",
    "for row in range(len(files_df)):\n",
    "    # Load the file\n",
    "    image_file = open(files_df['path'][row],'rb').read()\n",
    "    # Encode the file to a hexagsimal number\n",
    "    files_df['hash'][row] = hashlib.md5(image_file).hexdigest()\n",
    "    # Get the filename of the file\n",
    "    files_df['filename'][row] = os.path.basename(files_df['path'][row])\n",
    "    # Get the created date \n",
    "    files_df['created'][row] = pd.to_datetime(time.ctime(os.path.getctime(files_df['path'][row])))\n",
    "    # Get the modified date \n",
    "    files_df['modified'][row] = pd.to_datetime(time.ctime(os.path.getmtime(files_df['path'][row])))\n",
    "    # Get file size\n",
    "    files_df['filesize'][row] = os.path.getsize(files_df['path'][row])\n",
    "# Print first rows of the dataframe    \n",
    "files_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the total repeated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                  count\nhash                                   \n135a0a7b2f5eece7ce53c6fbb26e9cd9      3\n374f0604be4b276c023e330f409d2a7b      3\n4d0c606b822f16e97762a413b3e102c6      3\n74198ac70368792400a3a1a0900cc769      3\n933827ccd64bd5345025069ddc79451f      4\nb777dfc6904cee5e244c9da08bc84613      2\nef8cab05963a17a03072be7fdfe7daeb      2\nAll                                  20",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>hash</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>135a0a7b2f5eece7ce53c6fbb26e9cd9</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>374f0604be4b276c023e330f409d2a7b</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4d0c606b822f16e97762a413b3e102c6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>74198ac70368792400a3a1a0900cc769</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>933827ccd64bd5345025069ddc79451f</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>b777dfc6904cee5e244c9da08bc84613</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>ef8cab05963a17a03072be7fdfe7daeb</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>All</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Group repeated files by hash and summarize them\n",
    "reapeated_files_df = files_df.groupby('hash').sum()\n",
    "# Filter only files that are repeated - hash with more than 1 file\n",
    "reapeated_files_df = reapeated_files_df[reapeated_files_df['count'] > 1]\n",
    "# Summarize in a pivot table to have a total\n",
    "pivot_df = pd.pivot_table(reapeated_files_df, values='count', index=['hash'], aggfunc=np.sum, margins=True)\n",
    "# Create a unique identifier for the file name with the date and time\n",
    "now_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "# Export the file to a csv file for furure reference\n",
    "pivot_df.to_csv(now_string + ' - Duplicated' +  '.csv' )\n",
    "# Visualize the result\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all the files and the action to be taken for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                                                                                                      count  \\\nhash                             path                                               created             modified            filesize          \n135a0a7b2f5eece7ce53c6fbb26e9cd9 ../1/7612e4ee-b49a-46d2-94d9-fbc234c71b2e.jpg      2020-04-10 21:19:46 2020-04-07 14:38:28 110598        1   \n                                 ../1/New Folder With Items/7612e4ee-b49a-46d2-9... 2020-04-10 21:50:47 2020-04-07 14:38:28 110598        1   \n                                 ../1/New Folder With Items 3/7612e4ee-b49a-46d2... 2020-04-10 21:50:49 2020-04-07 14:38:28 110598        1   \n374f0604be4b276c023e330f409d2a7b ../1/639a58cd-e467-4187-91fe-35c71cc86970.jpg      2020-04-10 21:19:46 2020-04-08 19:08:52 45155         1   \n                                 ../1/New Folder With Items/639a58cd-e467-4187-9... 2020-04-10 21:50:47 2020-04-08 19:08:52 45155         1   \n                                 ../1/New Folder With Items 3/639a58cd-e467-4187... 2020-04-10 21:50:49 2020-04-08 19:08:52 45155         1   \n4d0c606b822f16e97762a413b3e102c6 ../1/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg      2020-04-10 21:19:46 2020-04-07 11:34:38 158673        1   \n                                 ../1/New Folder With Items/634fb9e9-4ca6-4ff3-a... 2020-04-10 21:50:47 2020-04-07 11:34:38 158673        1   \n                                 ../1/New Folder With Items 3/634fb9e9-4ca6-4ff3... 2020-04-10 21:50:49 2020-04-07 11:34:38 158673        1   \n74198ac70368792400a3a1a0900cc769 ../1/507c61f2-2cc9-46d9-8e0d-720a8ba8a3ba.jpg      2020-04-10 21:19:46 2020-04-07 15:13:46 219012        1   \n                                 ../1/New Folder With Items/507c61f2-2cc9-46d9-8... 2020-04-10 21:50:47 2020-04-07 15:13:46 219012        1   \n                                 ../1/New Folder With Items 3/507c61f2-2cc9-46d9... 2020-04-10 21:50:49 2020-04-07 15:13:46 219012        1   \n933827ccd64bd5345025069ddc79451f ../1/0009845a-53ab-4b7b-838e-3e76fa6a638f 2.jpg    2020-04-10 21:19:46 2020-04-07 15:13:26 211440        1   \n                                 ../1/New Folder With Items/0009845a-53ab-4b7b-8... 2020-04-10 21:50:47 2020-04-07 15:13:26 211440        1   \n                                 ../1/New Folder With Items 3/0009845a-53ab-4b7b... 2020-04-10 21:50:49 2020-04-07 15:13:26 211440        1   \n                                 ../1/New Folder With Items/0009845a-53ab-4b7b-8... 2020-04-10 21:51:03 2020-04-07 15:13:26 211440        1   \nb777dfc6904cee5e244c9da08bc84613 ../1/444f74e6-7d14-4324-a891-d53ab2109571.jpg      2020-04-10 21:19:46 2020-04-08 14:07:36 43238         1   \n                                 ../1/New Folder With Items/444f74e6-7d14-4324-a... 2020-04-10 21:51:03 2020-04-08 14:07:36 43238         1   \nef8cab05963a17a03072be7fdfe7daeb ../1/New Folder With Items/Escritorio copy 3.JPG   2020-04-10 21:19:33 2019-06-28 10:07:50 106405        1   \n                                 ../1/New Folder With Items/Escritorio copy 4.JPG   2020-04-10 21:51:06 2019-06-28 10:07:50 106405        1   \n\n                                                                                                                                      action  \nhash                             path                                               created             modified            filesize          \n135a0a7b2f5eece7ce53c6fbb26e9cd9 ../1/7612e4ee-b49a-46d2-94d9-fbc234c71b2e.jpg      2020-04-10 21:19:46 2020-04-07 14:38:28 110598      keep  \n                                 ../1/New Folder With Items/7612e4ee-b49a-46d2-9... 2020-04-10 21:50:47 2020-04-07 14:38:28 110598    delete  \n                                 ../1/New Folder With Items 3/7612e4ee-b49a-46d2... 2020-04-10 21:50:49 2020-04-07 14:38:28 110598    delete  \n374f0604be4b276c023e330f409d2a7b ../1/639a58cd-e467-4187-91fe-35c71cc86970.jpg      2020-04-10 21:19:46 2020-04-08 19:08:52 45155       Keep  \n                                 ../1/New Folder With Items/639a58cd-e467-4187-9... 2020-04-10 21:50:47 2020-04-08 19:08:52 45155     delete  \n                                 ../1/New Folder With Items 3/639a58cd-e467-4187... 2020-04-10 21:50:49 2020-04-08 19:08:52 45155     delete  \n4d0c606b822f16e97762a413b3e102c6 ../1/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg      2020-04-10 21:19:46 2020-04-07 11:34:38 158673      Keep  \n                                 ../1/New Folder With Items/634fb9e9-4ca6-4ff3-a... 2020-04-10 21:50:47 2020-04-07 11:34:38 158673    delete  \n                                 ../1/New Folder With Items 3/634fb9e9-4ca6-4ff3... 2020-04-10 21:50:49 2020-04-07 11:34:38 158673    delete  \n74198ac70368792400a3a1a0900cc769 ../1/507c61f2-2cc9-46d9-8e0d-720a8ba8a3ba.jpg      2020-04-10 21:19:46 2020-04-07 15:13:46 219012      Keep  \n                                 ../1/New Folder With Items/507c61f2-2cc9-46d9-8... 2020-04-10 21:50:47 2020-04-07 15:13:46 219012    delete  \n                                 ../1/New Folder With Items 3/507c61f2-2cc9-46d9... 2020-04-10 21:50:49 2020-04-07 15:13:46 219012    delete  \n933827ccd64bd5345025069ddc79451f ../1/0009845a-53ab-4b7b-838e-3e76fa6a638f 2.jpg    2020-04-10 21:19:46 2020-04-07 15:13:26 211440      Keep  \n                                 ../1/New Folder With Items/0009845a-53ab-4b7b-8... 2020-04-10 21:50:47 2020-04-07 15:13:26 211440    delete  \n                                 ../1/New Folder With Items 3/0009845a-53ab-4b7b... 2020-04-10 21:50:49 2020-04-07 15:13:26 211440    delete  \n                                 ../1/New Folder With Items/0009845a-53ab-4b7b-8... 2020-04-10 21:51:03 2020-04-07 15:13:26 211440    delete  \nb777dfc6904cee5e244c9da08bc84613 ../1/444f74e6-7d14-4324-a891-d53ab2109571.jpg      2020-04-10 21:19:46 2020-04-08 14:07:36 43238       Keep  \n                                 ../1/New Folder With Items/444f74e6-7d14-4324-a... 2020-04-10 21:51:03 2020-04-08 14:07:36 43238     delete  \nef8cab05963a17a03072be7fdfe7daeb ../1/New Folder With Items/Escritorio copy 3.JPG   2020-04-10 21:19:33 2019-06-28 10:07:50 106405      Keep  \n                                 ../1/New Folder With Items/Escritorio copy 4.JPG   2020-04-10 21:51:06 2019-06-28 10:07:50 106405    delete  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n      <th>action</th>\n    </tr>\n    <tr>\n      <th>hash</th>\n      <th>path</th>\n      <th>created</th>\n      <th>modified</th>\n      <th>filesize</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td rowspan=\"3\" valign=\"top\">135a0a7b2f5eece7ce53c6fbb26e9cd9</td>\n      <td>../1/7612e4ee-b49a-46d2-94d9-fbc234c71b2e.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 14:38:28</td>\n      <td>110598</td>\n      <td>1</td>\n      <td>keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/7612e4ee-b49a-46d2-94d9-fbc234c71b2e.jpg</td>\n      <td>2020-04-10 21:50:47</td>\n      <td>2020-04-07 14:38:28</td>\n      <td>110598</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items 3/7612e4ee-b49a-46d2-94d9-fbc234c71b2e.jpg</td>\n      <td>2020-04-10 21:50:49</td>\n      <td>2020-04-07 14:38:28</td>\n      <td>110598</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"3\" valign=\"top\">374f0604be4b276c023e330f409d2a7b</td>\n      <td>../1/639a58cd-e467-4187-91fe-35c71cc86970.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-08 19:08:52</td>\n      <td>45155</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/639a58cd-e467-4187-91fe-35c71cc86970.jpg</td>\n      <td>2020-04-10 21:50:47</td>\n      <td>2020-04-08 19:08:52</td>\n      <td>45155</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items 3/639a58cd-e467-4187-91fe-35c71cc86970.jpg</td>\n      <td>2020-04-10 21:50:49</td>\n      <td>2020-04-08 19:08:52</td>\n      <td>45155</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"3\" valign=\"top\">4d0c606b822f16e97762a413b3e102c6</td>\n      <td>../1/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 11:34:38</td>\n      <td>158673</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg</td>\n      <td>2020-04-10 21:50:47</td>\n      <td>2020-04-07 11:34:38</td>\n      <td>158673</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items 3/634fb9e9-4ca6-4ff3-a2d2-4ee81cfbde85.jpg</td>\n      <td>2020-04-10 21:50:49</td>\n      <td>2020-04-07 11:34:38</td>\n      <td>158673</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"3\" valign=\"top\">74198ac70368792400a3a1a0900cc769</td>\n      <td>../1/507c61f2-2cc9-46d9-8e0d-720a8ba8a3ba.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 15:13:46</td>\n      <td>219012</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/507c61f2-2cc9-46d9-8e0d-720a8ba8a3ba.jpg</td>\n      <td>2020-04-10 21:50:47</td>\n      <td>2020-04-07 15:13:46</td>\n      <td>219012</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items 3/507c61f2-2cc9-46d9-8e0d-720a8ba8a3ba.jpg</td>\n      <td>2020-04-10 21:50:49</td>\n      <td>2020-04-07 15:13:46</td>\n      <td>219012</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"4\" valign=\"top\">933827ccd64bd5345025069ddc79451f</td>\n      <td>../1/0009845a-53ab-4b7b-838e-3e76fa6a638f 2.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-07 15:13:26</td>\n      <td>211440</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/0009845a-53ab-4b7b-838e-3e76fa6a638f 2.jpg</td>\n      <td>2020-04-10 21:50:47</td>\n      <td>2020-04-07 15:13:26</td>\n      <td>211440</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items 3/0009845a-53ab-4b7b-838e-3e76fa6a638f 2.jpg</td>\n      <td>2020-04-10 21:50:49</td>\n      <td>2020-04-07 15:13:26</td>\n      <td>211440</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/0009845a-53ab-4b7b-838e-3e76fa6a638f 2 2.jpg</td>\n      <td>2020-04-10 21:51:03</td>\n      <td>2020-04-07 15:13:26</td>\n      <td>211440</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\" valign=\"top\">b777dfc6904cee5e244c9da08bc84613</td>\n      <td>../1/444f74e6-7d14-4324-a891-d53ab2109571.jpg</td>\n      <td>2020-04-10 21:19:46</td>\n      <td>2020-04-08 14:07:36</td>\n      <td>43238</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/444f74e6-7d14-4324-a891-d53ab2109571.jpg</td>\n      <td>2020-04-10 21:51:03</td>\n      <td>2020-04-08 14:07:36</td>\n      <td>43238</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\" valign=\"top\">ef8cab05963a17a03072be7fdfe7daeb</td>\n      <td>../1/New Folder With Items/Escritorio copy 3.JPG</td>\n      <td>2020-04-10 21:19:33</td>\n      <td>2019-06-28 10:07:50</td>\n      <td>106405</td>\n      <td>1</td>\n      <td>Keep</td>\n    </tr>\n    <tr>\n      <td>../1/New Folder With Items/Escritorio copy 4.JPG</td>\n      <td>2020-04-10 21:51:06</td>\n      <td>2019-06-28 10:07:50</td>\n      <td>106405</td>\n      <td>1</td>\n      <td>delete</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Validate if there are repeated files\n",
    "if pivot_df['count']['All'] ==0:\n",
    "    # If not repeated files, notify user\n",
    "    print('No repeated files were found')\n",
    "else:\n",
    "    # If there are repeated files\n",
    "    # Filter only files that are repeated, taken from the previous table summary\n",
    "    repeated_path_df = files_df[files_df['hash'].isin(pivot_df.index.to_list())]\n",
    "    # Group and sort rows by hash, path, created date, modified date and file size\n",
    "    # Ascending sorting for all columns except for file size. We want the biggest file (more detail)\n",
    "    repeated_path_df = repeated_path_df.groupby(['hash','path','created','modified','filesize']).sum().sort_values(by=['hash',                                                          'created','modified', 'filesize'],  ascending=[True, True, True, False])\n",
    "    # Initialize a column for the data frame to store the action for each file (keep/delete)    \n",
    "    repeated_path_df['action'] = ''\n",
    "    # Specify the action (keep) for the first row\n",
    "    repeated_path_df['action'][0] = 'keep' \n",
    "    # Keep the first file (earliest created and modified date and the biggest filesize) for every hash and delete the next ones\n",
    "    for i in range(1,len(repeated_path_df.index.get_level_values(1).tolist())):\n",
    "        if repeated_path_df.index.get_level_values(0)[i] == repeated_path_df.index.get_level_values(0)[i-1]:\n",
    "            # If the hash is the same as the previous row, delete it (Keep only the first one)\n",
    "            repeated_path_df['action'][i] = 'delete' \n",
    "        else:\n",
    "            # if hash changes compared to the last row, keep the file (don't delete it)\n",
    "            repeated_path_df['action'][i] = 'Keep'\n",
    "            # Store the file in a csv file with a unique identifier with date and time \n",
    "    repeated_path_df.to_csv(now_string + ' - Duplicated - Detail'  + '.csv' )\n",
    "repeated_path_df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-06f7af4d5966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreapeated_files_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreapeated_files_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'hspace'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wspace'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Duplicates'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Validate if there are repeated files\n",
    "if pivot_df['count']['All'] ==0:\n",
    "    # If not repeated files, notify user\n",
    "    print('No repeated files were found')\n",
    "else:\n",
    "    rows = len(reapeated_files_df.index.to_list())\n",
    "    columns = reapeated_files_df['count'].max()\n",
    "    fig, axs = plt.subplots(rows,columns, gridspec_kw={'hspace': 0.1, 'wspace': 0})\n",
    "    fig.set_size_inches((15*columns,15*rows))\n",
    "    fig.suptitle('Duplicates', fontsize=50)\n",
    "\n",
    "    for k in range(rows):\n",
    "        for l in range(columns):\n",
    "            axs[k,l].axis('off')\n",
    "            axs[k,l].axes.xaxis.set_ticklabels([])\n",
    "            axs[k,l].axes.yaxis.set_ticklabels([])\n",
    "            axs[k,l].axes.xaxis.set_ticks([])\n",
    "            axs[k,l].axes.yaxis.set_ticks([])\n",
    "\n",
    "    k=0\n",
    "    l=0\n",
    "\n",
    "    image_path = os.path.join(repeated_path_df.index.get_level_values(1)[0])\n",
    "    img = mpimg.imread(image_path)  \n",
    "    axs[k,l].imshow(img)\n",
    "    axs[k,l].axis('on')\n",
    "    axs[k,l].set_title(repeated_path_df['action'][0], fontsize=36);\n",
    "\n",
    "    for i in range(1,len(repeated_path_df.index.get_level_values(1).tolist())):\n",
    "        if repeated_path_df.index.get_level_values(0)[i] == repeated_path_df.index.get_level_values(0)[i-1]:\n",
    "            # If the hash is the same as the previous row, delete it (Keep only the first one)\n",
    "            l+=1\n",
    "        else:\n",
    "            # if hash changes compared to the last row, keep the file (don't delete it)\n",
    "            k+=1\n",
    "            l=0\n",
    "    \n",
    "            image_path = os.path.join(repeated_path_df.index.get_level_values(1)[i])\n",
    "            img = mpimg.imread(image_path)\n",
    "            axs[k,l].imshow(img)\n",
    "            axs[k,l].axis('off')\n",
    "            axs[k,l].set_title(repeated_path_df['action'][i], fontsize=36);\n",
    "\n",
    "\n",
    "        plt.savefig(now_string + ' - Duplicated' + '.jpg', dpi=300, pad_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = input(\"Do you want to delete the files(Y/N)?: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No files were deleted\n"
    }
   ],
   "source": [
    "if pivot_df['count']['All'] ==0:\n",
    "    print('No repeated files were found')\n",
    "\n",
    "else:\n",
    "    if txt == 'Y':\n",
    "        for i in range(0,len(repeated_path_df.index.get_level_values(1).tolist())):\n",
    "            if repeated_path_df['action'][i] == 'delete':\n",
    "                os.remove(repeated_path_df.index.get_level_values(1).tolist()[i])\n",
    "        print('All duplicated images had been deleted')                \n",
    "    else:\n",
    "        print('No files were deleted')\n",
    "\n",
    ""
   ]
  }
 ]
}